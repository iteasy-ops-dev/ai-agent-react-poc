import json
import time
from typing import Dict, List, Any, Optional
from abc import ABC, abstractmethod
from core.model import LLMClient
from tools.tools_manager import ToolsManager


class ReasoningCallback(ABC):
    """
    ì½œë°± ì¸í„°í˜ì´ìŠ¤ - ReAct ë£¨í”„ì˜ ê° ë‹¨ê³„ì—ì„œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ì œê³µ
    """
    
    @abstractmethod
    def on_iteration_start(self, iteration: int, max_iterations: int):
        """ìƒˆë¡œìš´ ë°˜ë³µ ì‹œì‘"""
        pass
    
    @abstractmethod
    def on_reasoning(self, iteration: int, thought: str):
        """LLMì˜ ì¶”ë¡  ê³¼ì •"""
        pass
    
    @abstractmethod
    def on_tool_call(self, iteration: int, tool: str, arguments: Dict[str, Any]):
        """ë„êµ¬ í˜¸ì¶œ ì‹œì‘"""
        pass
    
    @abstractmethod
    def on_tool_result(self, iteration: int, tool: str, result: str, success: bool):
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼"""
        pass
    
    @abstractmethod
    def on_observation(self, iteration: int, observation: str):
        """ê´€ì°° ë‹¨ê³„"""
        pass
    
    @abstractmethod
    def on_iteration_end(self, iteration: int):
        """ë°˜ë³µ ì¢…ë£Œ"""
        pass
    
    @abstractmethod
    def on_final_result(self, result: str, iterations: int):
        """ìµœì¢… ê²°ê³¼"""
        pass
    
    @abstractmethod
    def on_error(self, iteration: int, error: str):
        """ì˜¤ë¥˜ ë°œìƒ"""
        pass


class DefaultCallback(ReasoningCallback):
    """
    ê¸°ë³¸ ì½œë°± êµ¬í˜„ - ì½˜ì†” ì¶œë ¥ìš©
    """
    
    def on_iteration_start(self, iteration: int, max_iterations: int):
        print(f"\n{'='*60}")
        print(f"ğŸ”„ ë°˜ë³µ {iteration}/{max_iterations} ì‹œì‘")
        print(f"{'='*60}")
    
    def on_reasoning(self, _iteration: int, thought: str):
        print(f"\nğŸ¤” ì¶”ë¡  ê³¼ì •:")
        print(f"   {thought}")
    
    def on_tool_call(self, _iteration: int, tool: str, arguments: Dict[str, Any]):
        print(f"\nğŸ”§ ë„êµ¬ í˜¸ì¶œ: {tool}")
        print(f"   ì¸ì: {json.dumps(arguments, ensure_ascii=False, indent=2)}")
    
    def on_tool_result(self, _iteration: int, _tool: str, result: str, success: bool):
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"\nğŸ“Š ë„êµ¬ ê²°ê³¼ [{status}]:")
        preview = result[:200] + "..." if len(result) > 200 else result
        print(f"   {preview}")
    
    def on_observation(self, _iteration: int, observation: str):
        print(f"\nğŸ‘ï¸ ê´€ì°°:")
        print(f"   {observation}")
    
    def on_iteration_end(self, iteration: int):
        print(f"\n{'='*60}")
        print(f"âœ… ë°˜ë³µ {iteration} ì™„ë£Œ")
        print(f"{'='*60}")
    
    def on_final_result(self, result: str, iterations: int):
        print(f"\n{'ğŸ¯'*30}")
        print(f"ìµœì¢… ê²°ê³¼ (ì´ {iterations}íšŒ ë°˜ë³µ):")
        print(result)
        print(f"{'ğŸ¯'*30}")
    
    def on_error(self, iteration: int, error: str):
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ (ë°˜ë³µ {iteration}):")
        print(f"   {error}")


class ReactAgentV2:
    """
    ê°œì„ ëœ ReAct ì—ì´ì „íŠ¸ - ì‹¤ì‹œê°„ ì¶”ë¡  ê³¼ì • í‘œì‹œ ì§€ì›
    
    ì£¼ìš” ê°œì„ ì‚¬í•­:
    1. ì½œë°± ì‹œìŠ¤í…œìœ¼ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì œê³µ
    2. ì¶”ë¡  ê³¼ì •ì„ ëª…í™•íˆ ë¶„ë¦¬í•˜ì—¬ í‘œì‹œ
    3. êµ¬ì¡°í™”ëœ ì‹¤í–‰ ë¡œê·¸ë¡œ ê° ë‹¨ê³„ ì¶”ì 
    """
    
    def __init__(
        self,
        endpoint: str = "http://localhost:11434",
        model: str = "gpt-oss:20b",
        max_iterations: int = 10,
        system_prompt: Optional[str] = None,
        callback: Optional[ReasoningCallback] = None,
        verbose: bool = True
    ):
        """
        ReactAgentV2 ì´ˆê¸°í™”
        
        Args:
            endpoint: LLM ì„œë²„ ì—”ë“œí¬ì¸íŠ¸
            model: ì‚¬ìš©í•  ëª¨ë¸ëª…
            max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
            system_prompt: ì‚¬ìš©ì ì •ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            callback: ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì½œë°± ê°ì²´
            verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
        """
        self.endpoint = endpoint
        self.model = model
        self.max_iterations = max_iterations
        self.verbose = verbose
        
        # ì½œë°± ì„¤ì • (ì—†ìœ¼ë©´ ê¸°ë³¸ ì½œë°± ì‚¬ìš©)
        self.callback = callback or DefaultCallback()
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.llm_client = LLMClient(endpoint=endpoint, model=model)
        self.tools_manager = ToolsManager()
        
        # ì‹¤í–‰ ìƒíƒœ
        self.current_iteration = 0
        self.conversation_history = []
        self.execution_log = []
        self.reasoning_history = []  # ì¶”ë¡  ê³¼ì • ì €ì¥
        self.token_usage_history = []  # ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ì €ì¥
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.system_prompt = system_prompt or self._get_default_system_prompt()
        
        # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
        self._initialize_conversation()
    
    def _get_default_system_prompt(self) -> str:
        """
        ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± - ì°¸ì¡° íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì„ ëœ ì²´ê³„ì  í”„ë¡¬í”„íŠ¸
        """
        available_tools = self.tools_manager.get_available_tools()
        tools_info = []
        
        for tool_name in available_tools:
            tool_info = self.tools_manager.get_tool_info(tool_name)
            tools_info.append(f"- {tool_name}: {tool_info.get('description', 'No description')}")
        
        tools_list = "\n".join(tools_info)
        
        return f"""
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì‹œìŠ¤í…œ ë¶„ì„ ë° ë¬¸ì œ í•´ê²° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ReAct(Reasoning-Acting-Observing) íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
{tools_list}

## ReAct ë¶„ì„ í”„ë ˆì„ì›Œí¬:
ë‹¤ìŒ 5ë‹¨ê³„ ì¶”ë¡  ê³¼ì •ì„ ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”:

### 1ï¸âƒ£ ê´€ì°°(Observation)
- í˜„ì¬ ìƒí™© íŒŒì•… ë° ì •ë³´ ìˆ˜ì§‘ ê³„íš ìˆ˜ë¦½
- í•„ìš”í•œ ì •ë³´ì˜ ìš°ì„ ìˆœìœ„ ê²°ì •
- íš¨ìœ¨ì ì¸ ì •ë³´ ìˆ˜ì§‘ ì „ëµ ìˆ˜ë¦½

### 2ï¸âƒ£ ë¶„ì„(Analysis)
- ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ íŒ¨í„´ ë¶„ì„ ë° ê·¼ë³¸ ì›ì¸ íŒŒì•…
- ìƒê´€ê´€ê³„ ë° ì¸ê³¼ê´€ê³„ ì‹ë³„
- ë¬¸ì œì˜ í•µì‹¬ ìš”ì†Œ ì¶”ì¶œ

### 3ï¸âƒ£ ê³„íš(Planning)
- ìš°ì„ ìˆœìœ„ë³„ ë‹¤ë‹¨ê³„ ì¡°ì¹˜ ê³„íš ìˆ˜ë¦½
- ë¦¬ìŠ¤í¬ í‰ê°€ ë° ëŒ€ì•ˆ ì¤€ë¹„
- ë‹¨ê³„ë³„ ê²€ì¦ í¬ì¸íŠ¸ ì„¤ì •

### 4ï¸âƒ£ ì‹¤í–‰(Execution)
- ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•œ íš¨ìœ¨ì  ì‘ì—… ìˆ˜í–‰
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ ì‘ì—… ë™ì‹œ ìˆ˜í–‰
- ì‹¤ì‹œê°„ í”¼ë“œë°± ë°˜ì˜

### 5ï¸âƒ£ ê²€ì¦(Validation)
- ê²°ê³¼ ê²€ì¦ ë° ëª©í‘œ ë‹¬ì„±ë„ í‰ê°€
- ì¶”ê°€ ì¡°ì¹˜ í•„ìš”ì„± íŒë‹¨
- ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

## Best Practices:

### íš¨ìœ¨ì ì¸ ë„êµ¬ ì‚¬ìš©:
- **ë°°ì¹˜ ì²˜ë¦¬**: ê°€ëŠ¥í•œ ì—¬ëŸ¬ ì‘ì—…ì„ í•œ ë²ˆì— ìˆ˜í–‰
- **ì ì§„ì  íƒìƒ‰**: ê¸°ë³¸ ì •ë³´ â†’ ìƒì„¸ ì •ë³´ â†’ ì‹¬í™” ë¶„ì„ ìˆœì„œ
- **ì¬ì‚¬ìš©**: ì´ì „ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ì¤‘ë³µ ì‘ì—… ë°©ì§€

### ë¶„ì„ ì›ì¹™:
- **ì •ëŸ‰ì  ë¶„ì„**: ìˆ˜ì¹˜ì™€ ë©”íŠ¸ë¦­ ê¸°ë°˜ í‰ê°€
- **ìœ„í—˜ë„ í‰ê°€**: ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ë¶„ë¥˜
- **ê·¼ê±° ì œì‹œ**: ëª¨ë“  ê²°ë¡ ì— ëª…í™•í•œ ê·¼ê±° ì œê³µ

## ì‘ë‹µ êµ¬ì¡°:

### ì¶”ë¡  ë‹¨ê³„ì—ì„œ:
"ğŸ¤” í˜„ì¬ ìƒí™©: [ìƒí™© ì„¤ëª…]
ğŸ“Š í•„ìš”í•œ ì •ë³´: [ìˆ˜ì§‘í•  ì •ë³´ ëª©ë¡]
ğŸ¯ ë‹¤ìŒ í–‰ë™: [ìˆ˜í–‰í•  ì‘ì—…]"

### ë„êµ¬ í˜¸ì¶œ ì‹œ:
"ğŸ”§ ë„êµ¬ ì„ íƒ ì´ìœ : [ì™œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€]
ğŸ“¥ ì˜ˆìƒ ê²°ê³¼: [ê¸°ëŒ€í•˜ëŠ” ì •ë³´ë‚˜ ê²°ê³¼]"

### ê´€ì°° ë‹¨ê³„ì—ì„œ:
"ğŸ‘ï¸ ìˆ˜ì§‘ëœ ì •ë³´: [í•µì‹¬ ë°œê²¬ì‚¬í•­]
ğŸ’¡ ì¸ì‚¬ì´íŠ¸: [ë°ì´í„°ê°€ ì˜ë¯¸í•˜ëŠ” ê²ƒ]
â¡ï¸ ë‹¤ìŒ ë‹¨ê³„: [ì¶”ê°€ í•„ìš” ì‘ì—…]"

## ìµœì¢… ë³´ê³ ì„œ í˜•ì‹:

1. **ìš”ì•½**: í•µì‹¬ ë°œê²¬ì‚¬í•­ê³¼ ê²°ë¡ 
2. **ìƒì„¸ ë¶„ì„**: 
   - ìˆ˜ì§‘ëœ ë°ì´í„°
   - ë¶„ì„ ê³¼ì •
   - ì£¼ìš” ë°œê²¬ì‚¬í•­
3. **ê¶Œì¥ì‚¬í•­**: ìš°ì„ ìˆœìœ„ë³„ ì¡°ì¹˜ ì‚¬í•­
4. **ìœ„í—˜ ìš”ì†Œ**: ì£¼ì˜í•´ì•¼ í•  ì 
5. **ë‹¤ìŒ ë‹¨ê³„**: í›„ì† ì‘ì—… ì œì•ˆ

## ì¤‘ìš” ì§€ì¹¨:
1. ê° ë°˜ë³µë§ˆë‹¤ ëª…í™•í•œ ì¶”ë¡  ê³¼ì •ì„ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”
2. ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê¸° ì „ì— ì™œ ê·¸ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ ì„¤ëª…í•˜ì„¸ìš”
3. ê²°ê³¼ë¥¼ ë°›ì€ í›„ ê·¸ ì˜ë¯¸ë¥¼ í•´ì„í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê³„íší•˜ì„¸ìš”
4. ë¶ˆí™•ì‹¤í•œ ê²½ìš° ì¶”ê°€ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”
5. ìµœì¢… ë‹µë³€ì€ ì²´ê³„ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”

ì´ì œ ì£¼ì–´ì§„ ì‘ì—…ì„ ReAct íŒ¨í„´ìœ¼ë¡œ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤.
"""
    
    def _initialize_conversation(self):
        """ëŒ€í™” ì´ˆê¸°í™”"""
        self.conversation_history = [
            {"role": "system", "content": self.system_prompt}
        ]
        self.reasoning_history = []
        self.execution_log = []
        self.token_usage_history = []  # ì´ˆê¸°í™” ì‹œì—ë„ í† í° íˆìŠ¤í† ë¦¬ ë¦¬ì…‹
    
    def run(self, user_input: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•´ ReAct íŒ¨í„´ìœ¼ë¡œ ì²˜ë¦¬
        
        Args:
            user_input: ì‚¬ìš©ì ìš”ì²­
            
        Returns:
            ì‹¤í–‰ ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„°
        """
        start_time = time.time()
        self.current_iteration = 0
        self.execution_log = []
        self.reasoning_history = []
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        self.conversation_history.append({
            "role": "user",
            "content": user_input
        })
        
        try:
            # ReAct ë£¨í”„ ì‹¤í–‰
            final_result = self._react_loop()
            
            execution_time = time.time() - start_time
            
            # í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ ìˆ˜ì§‘
            total_token_usage = self._calculate_total_token_usage()
            
            # ìµœì¢… ê²°ê³¼ ì½œë°±
            self.callback.on_final_result(final_result, self.current_iteration)
            
            return {
                "success": True,
                "result": final_result,
                "iterations": self.current_iteration,
                "execution_time": round(execution_time, 2),
                "tools_used": [log["tool"] for log in self.execution_log if log.get("type") == "tool_call"],
                "conversation_length": len(self.conversation_history),
                "token_usage": total_token_usage,
                "reasoning_history": self.reasoning_history.copy(),
                "execution_log": self.execution_log.copy()
            }
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"ReAct ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            
            self.callback.on_error(self.current_iteration, error_msg)
            
            return {
                "success": False,
                "error": error_msg,
                "iterations": self.current_iteration,
                "execution_time": round(execution_time, 2),
                "conversation_length": len(self.conversation_history),
                "tools_used": [log["tool"] for log in self.execution_log if log.get("type") == "tool_call"],
                "reasoning_history": self.reasoning_history.copy(),
                "execution_log": self.execution_log.copy()
            }
    
    def _react_loop(self) -> str:
        """
        ReAct íŒ¨í„´ì˜ í•µì‹¬ ë£¨í”„ - ê°œì„ ëœ ì¶”ë¡  ê³¼ì • ì¶”ì 
        """
        while self.current_iteration < self.max_iterations:
            self.current_iteration += 1
            
            # ë°˜ë³µ ì‹œì‘ ì½œë°±
            self.callback.on_iteration_start(self.current_iteration, self.max_iterations)
            
            # í˜„ì¬ ë°˜ë³µ ì •ë³´ë¥¼ ì‹¤í–‰ ë¡œê·¸ì— ì¶”ê°€
            iteration_log = {
                "iteration": self.current_iteration,
                "timestamp": time.time(),
                "reasoning": None,
                "tool_calls": [],
                "observations": []
            }
            
            try:
                # LLM ì‘ë‹µ ìƒì„±
                response = self._get_llm_response()
                
                if not response.get("success", False):
                    raise Exception(f"LLM ì‘ë‹µ ì‹¤íŒ¨: {response.get('error', 'Unknown error')}")
                
                message = response.get("message")
                finish_reason = response.get("finish_reason")
                
                # ì¶”ë¡  ê³¼ì • ì¶”ì¶œ - ì‹¤ì œ reasoning ì†ì„± ìš°ì„  ì‚¬ìš©
                reasoning = response.get("reasoning")  # LLMì—ì„œ ì œê³µí•˜ëŠ” ì‹¤ì œ reasoning
                if not reasoning:
                    # í´ë°±: ì‘ë‹µ ë‚´ìš©ì—ì„œ ì¶”ë¡  ê³¼ì • ì¶”ì¶œ
                    reasoning = self._extract_reasoning(message.content)
                
                if reasoning:
                    iteration_log["reasoning"] = reasoning
                    self.reasoning_history.append({
                        "iteration": self.current_iteration,
                        "reasoning": reasoning,
                        "timestamp": time.time()
                    })
                    
                    # ì¶”ë¡  ì½œë°±
                    self.callback.on_reasoning(self.current_iteration, reasoning)
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì‘ë‹µ ì¶”ê°€
                self.conversation_history.append(message.model_dump())
                
                # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ìµœì¢… ì‘ë‹µìœ¼ë¡œ ê°„ì£¼
                if finish_reason != "tool_calls" or not hasattr(message, 'tool_calls'):
                    final_response = message.content or "ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                    
                    # ìµœì¢… ê´€ì°° ì½œë°±
                    self.callback.on_observation(self.current_iteration, "ìµœì¢… ê²°ë¡  ë„ë‹¬")
                    
                    # ë°˜ë³µ ì¢…ë£Œ ì½œë°±
                    self.callback.on_iteration_end(self.current_iteration)
                    
                    self.execution_log.append(iteration_log)
                    return final_response
                
                # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
                tool_results = self._process_tool_calls(message.tool_calls, iteration_log)
                
                # ë„êµ¬ ê²°ê³¼ì— ëŒ€í•œ ê´€ì°°
                if tool_results:
                    observation = self._generate_observation(tool_results)
                    iteration_log["observations"].append(observation)
                    
                    # ê´€ì°° ì½œë°±
                    self.callback.on_observation(self.current_iteration, observation)
                
                # ë°˜ë³µ ì¢…ë£Œ ì½œë°±
                self.callback.on_iteration_end(self.current_iteration)
                
                # ì‹¤í–‰ ë¡œê·¸ì— ì¶”ê°€
                self.execution_log.append(iteration_log)
                
            except Exception as e:
                error_msg = f"ë°˜ë³µ {self.current_iteration}ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                
                # ì˜¤ë¥˜ ì½œë°±
                self.callback.on_error(self.current_iteration, str(e))
                
                # ì˜¤ë¥˜ ë¡œê·¸ ì¶”ê°€
                iteration_log["error"] = str(e)
                self.execution_log.append(iteration_log)
                
                # ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ì•„ë‹ˆë©´ ê³„ì† ì§„í–‰
                if self.current_iteration < self.max_iterations - 1:
                    continue
                else:
                    raise Exception(error_msg)
        
        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ - ë¶€ë¶„ì ì¸ ê²°ë¡  ìƒì„±
        partial_conclusion = self._generate_partial_conclusion()
        
        # ê²½ê³  ì½œë°± (ë¶€ë¶„ ê²°ë¡ ì˜ ì²« ë²ˆì§¸ ì¤„ë§Œ ì‚¬ìš©)
        warning_msg = partial_conclusion.split('\n')[0] if partial_conclusion else f"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ({self.max_iterations}) ë„ë‹¬"
        self.callback.on_observation(self.current_iteration, warning_msg)
        
        return partial_conclusion
    
    def _extract_reasoning(self, content: Optional[str]) -> Optional[str]:
        """
        LLM ì‘ë‹µì—ì„œ ì¶”ë¡  ê³¼ì • ì¶”ì¶œ (í´ë°±ìš©)
        ì‹¤ì œ reasoning ì†ì„±ì´ ì—†ì„ ë•Œë§Œ ì‚¬ìš©
        
        Args:
            content: LLM ì‘ë‹µ ë‚´ìš©
            
        Returns:
            ì¶”ì¶œëœ ì¶”ë¡  ê³¼ì • ë˜ëŠ” None
        """
        if not content:
            return None
        
        # ì¶”ë¡  ê´€ë ¨ í‚¤ì›Œë“œ íŒ¨í„´ (ë” ì—„ê²©í•˜ê²Œ)
        reasoning_patterns = [
            "ğŸ¤” í˜„ì¬ ìƒí™©:",
            "ğŸ“Š í•„ìš”í•œ ì •ë³´:",
            "ğŸ¯ ë‹¤ìŒ í–‰ë™:",
            "ë¶„ì„:",
            "ì¶”ë¡ :",
            "ê³„íš:",
            "ê´€ì°°:"
        ]
        
        # ì‘ë‹µì—ì„œ ì¶”ë¡  ë¶€ë¶„ ì°¾ê¸°
        for pattern in reasoning_patterns:
            if pattern in content:
                # íŒ¨í„´ì´ ë°œê²¬ë˜ë©´ ì¶”ë¡ ìœ¼ë¡œ ê°„ì£¼
                return content.strip()
        
        # ë” ì—„ê²©í•œ ì¡°ê±´: ëª…í™•í•œ ì¶”ë¡  ì˜ë„ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜
        # ìµœì¢… ë‹µë³€ê³¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´
        if any(keyword in content.lower() for keyword in ["ìƒê°í•´ë³´ê² ìŠµë‹ˆë‹¤", "ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤", "í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤"]):
            return content.strip()
        
        return None
    
    def _get_llm_response(self) -> Dict[str, Any]:
        """LLMìœ¼ë¡œë¶€í„° ì‘ë‹µ íšë“"""
        # ë„êµ¬ ìŠ¤í‚¤ë§ˆ ê°€ì ¸ì˜¤ê¸°
        tools_schemas = self.tools_manager.get_tools_schemas()
        
        # LLM í˜¸ì¶œ
        response = self.llm_client.chat_completion(
            messages=self.conversation_history,
            tools=tools_schemas if tools_schemas else None,
            temperature=0.7
        )
        
        # ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ì €ì¥ (ìˆëŠ” ê²½ìš°)
        if response.get("success") and response.get("usage"):
            usage_info = {
                "iteration": self.current_iteration,
                "timestamp": time.time(),
                "usage": response["usage"],
                "type": "llm_response"
            }
            self.token_usage_history.append(usage_info)
        
        return response
    
    def _process_tool_calls(self, tool_calls: List[Any], iteration_log: Dict) -> List[Dict]:
        """
        ë„êµ¬ í˜¸ì¶œë“¤ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ ë°˜í™˜
        
        Args:
            tool_calls: ë„êµ¬ í˜¸ì¶œ ëª©ë¡
            iteration_log: í˜„ì¬ ë°˜ë³µì˜ ë¡œê·¸
            
        Returns:
            ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ëª©ë¡
        """
        results = []
        
        for tool_call in tool_calls:
            if tool_call.type == "function":
                result = self._execute_single_tool(tool_call, iteration_log)
                results.append(result)
        
        return results
    
    def _execute_single_tool(self, tool_call, iteration_log: Dict) -> Dict:
        """
        ë‹¨ì¼ ë„êµ¬ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜
        
        Args:
            tool_call: ë„êµ¬ í˜¸ì¶œ ì •ë³´
            iteration_log: í˜„ì¬ ë°˜ë³µì˜ ë¡œê·¸
            
        Returns:
            ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
        """
        function_name = tool_call.function.name
        function_args = json.loads(tool_call.function.arguments)
        tool_call_id = tool_call.id
        
        # ë„êµ¬ í˜¸ì¶œ ì½œë°±
        self.callback.on_tool_call(self.current_iteration, function_name, function_args)
        
        # ë„êµ¬ í˜¸ì¶œ ë¡œê·¸
        tool_log = {
            "tool": function_name,
            "arguments": function_args,
            "timestamp": time.time(),
            "tool_call_id": tool_call_id
        }
        
        try:
            # ë„êµ¬ ì‹¤í–‰
            result = self.tools_manager.execute_tool(function_name, function_args)
            
            tool_log["success"] = True
            tool_log["result"] = result
            tool_log["result_length"] = len(str(result))
            
            # ë„êµ¬ ê²°ê³¼ ì½œë°±
            self.callback.on_tool_result(
                self.current_iteration,
                function_name,
                result,
                True
            )
            
            # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history.append({
                "role": "tool",
                "content": str(result),
                "tool_call_id": tool_call_id
            })
            
        except Exception as e:
            error_msg = f"ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
            tool_log["success"] = False
            tool_log["error"] = str(e)
            result = error_msg
            
            # ë„êµ¬ ì˜¤ë¥˜ ì½œë°±
            self.callback.on_tool_result(
                self.current_iteration,
                function_name,
                error_msg,
                False
            )
            
            # ì˜¤ë¥˜ ê²°ê³¼ë„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history.append({
                "role": "tool",
                "content": f"ì˜¤ë¥˜: {error_msg}",
                "tool_call_id": tool_call_id
            })
        
        # ë°˜ë³µ ë¡œê·¸ì— ë„êµ¬ í˜¸ì¶œ ì¶”ê°€
        iteration_log["tool_calls"].append(tool_log)
        
        # ì „ì²´ ì‹¤í–‰ ë¡œê·¸ì—ë„ ì¶”ê°€
        self.execution_log.append({
            "iteration": self.current_iteration,
            "type": "tool_call",
            **tool_log
        })
        
        return tool_log
    
    def _generate_observation(self, tool_results: List[Dict]) -> str:
        """
        ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¡œë¶€í„° ê´€ì°° ìƒì„±
        
        Args:
            tool_results: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ëª©ë¡
            
        Returns:
            ê´€ì°° ë‚´ìš©
        """
        observations = []
        
        for result in tool_results:
            if result.get("success"):
                observations.append(f"{result['tool']} ì‹¤í–‰ ì„±ê³µ")
            else:
                observations.append(f"{result['tool']} ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
        
        return ", ".join(observations) if observations else "ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ"
    
    def _generate_partial_conclusion(self) -> str:
        """
        ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ ë¶€ë¶„ì ì¸ ê²°ë¡  ìƒì„±
        
        ì‹¤í–‰ ë¡œê·¸ì™€ ì¶”ë¡  íˆìŠ¤í† ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ë¶€ë¶„ ê²°ê³¼ë¥¼ ì œì‹œ
        
        Returns:
            ë¶€ë¶„ì ì¸ ë¶„ì„ ê²°ê³¼ì™€ ê¶Œì¥ì‚¬í•­
        """
        if not self.execution_log and not self.reasoning_history:
            return "ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¬¸ì œë¥¼ ë‹¨ìˆœí™”í•˜ê±°ë‚˜ ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."
        
        # ì™„ë£Œëœ ì‘ì—… ë¶„ì„
        completed_tools = []
        successful_tools = []
        failed_tools = []
        key_insights = []
        
        # ì‹¤í–‰ ë¡œê·¸ì—ì„œ ë„êµ¬ ì‚¬ìš© í˜„í™© ë¶„ì„
        for log_entry in self.execution_log:
            if log_entry.get("type") == "tool_call":
                tool_name = log_entry.get("tool")
                if tool_name:
                    completed_tools.append(tool_name)
                    if log_entry.get("success", False):
                        successful_tools.append(tool_name)
                        # ì„±ê³µí•œ ë„êµ¬ì˜ ê²°ê³¼ì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
                        result = log_entry.get("result", "")
                        if result and len(str(result)) > 50:
                            preview = str(result)[:200] + "..." if len(str(result)) > 200 else str(result)
                            key_insights.append(f"â€¢ {tool_name}: {preview}")
                    else:
                        failed_tools.append(f"{tool_name} ({log_entry.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')})")
        
        # ì¶”ë¡  íˆìŠ¤í† ë¦¬ì—ì„œ í•µì‹¬ ì‚¬ê³  ê³¼ì • ì¶”ì¶œ
        reasoning_insights = []
        for reasoning_entry in self.reasoning_history[-3:]:  # ìµœê·¼ 3ê°œ ì¶”ë¡ ë§Œ
            reasoning = reasoning_entry.get("reasoning", "")
            if reasoning and len(reasoning) > 30:
                # í•µì‹¬ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¶”ë¡ ë§Œ ì„ ë³„
                if any(keyword in reasoning.lower() for keyword in 
                       ["ë¶„ì„", "ë°œê²¬", "ë¬¸ì œ", "í•´ê²°", "ê°œì„ ", "ì¶”ì²œ", "ê²°ë¡ ", "ì¤‘ìš”"]):
                    preview = reasoning[:150] + "..." if len(reasoning) > 150 else reasoning
                    reasoning_insights.append(f"â€¢ {preview}")
        
        # ì „ì²´ ëŒ€í™”ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ ì¶”ì¶œ
        important_context = []
        if len(self.conversation_history) > 2:  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì‚¬ìš©ì ì§ˆë¬¸ ì´í›„
            for message in self.conversation_history[2:]:  # ì‹¤ì œ ëŒ€í™” ë‚´ìš©ë§Œ
                if message.get("role") == "assistant" and message.get("content"):
                    content = message["content"]
                    # êµ¬ì²´ì ì¸ ì •ë³´ë‚˜ ê²°ê³¼ê°€ í¬í•¨ëœ ì‘ë‹µë§Œ ì„ ë³„
                    if any(indicator in content.lower() for indicator in 
                           ["ë°œê²¬í–ˆìŠµë‹ˆë‹¤", "í™•ì¸í–ˆìŠµë‹ˆë‹¤", "ë¶„ì„ ê²°ê³¼", "ê¶Œì¥ì‚¬í•­", "í•´ê²°ì±…"]):
                        preview = content[:200] + "..." if len(content) > 200 else content
                        important_context.append(f"â€¢ {preview}")
        
        # ë¶€ë¶„ ê²°ë¡  êµ¬ì„±
        conclusion_parts = [
            f"âš ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ({self.max_iterations}) ë„ë‹¬ë¡œ ë¶„ì„ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "",
            "## ğŸ“Š í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©"
        ]
        
        if completed_tools:
            conclusion_parts.extend([
                f"**ì‹¤í–‰ëœ ì‘ì—…**: {len(completed_tools)}ê°œ ë„êµ¬ ì‚¬ìš©",
                f"- ì„±ê³µ: {len(successful_tools)}ê°œ ({', '.join(set(successful_tools))})",
            ])
            if failed_tools:
                conclusion_parts.append(f"- ì‹¤íŒ¨: {len(failed_tools)}ê°œ ({', '.join(failed_tools)})")
        
        if key_insights:
            conclusion_parts.extend([
                "",
                "## ğŸ” ìˆ˜ì§‘ëœ ì£¼ìš” ì •ë³´",
                *key_insights[:5]  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            ])
        
        if reasoning_insights:
            conclusion_parts.extend([
                "",
                "## ğŸ¤” í•µì‹¬ ë¶„ì„ ë‚´ìš©",
                *reasoning_insights[:3]  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            ])
        
        if important_context:
            conclusion_parts.extend([
                "",
                "## ğŸ’¡ ì£¼ìš” ë°œê²¬ì‚¬í•­",
                *important_context[:3]  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            ])
        
        # ê¶Œì¥ì‚¬í•­ ì¶”ê°€
        conclusion_parts.extend([
            "",
            "## ğŸ¯ ê¶Œì¥ì‚¬í•­",
            "â€¢ ë¬¸ì œë¥¼ ë” êµ¬ì²´ì ì´ê³  ë‹¨ìˆœí•œ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”",
            "â€¢ íŠ¹ì • ë¶€ë¶„ì— ì§‘ì¤‘í•˜ì—¬ ë‹¨ê³„ë³„ë¡œ ì ‘ê·¼í•´ë³´ì„¸ìš”",
            f"â€¢ max_iterations ê°’ì„ {self.max_iterations + 5} ì´ìƒìœ¼ë¡œ ì¦ê°€ì‹œì¼œ ì¬ì‹œë„í•˜ì„¸ìš”"
        ])
        
        if successful_tools:
            conclusion_parts.append("â€¢ ì„±ê³µí•œ ì‘ì—… ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê³„íší•˜ì„¸ìš”")
        
        if failed_tools:
            conclusion_parts.append("â€¢ ì‹¤íŒ¨í•œ ì‘ì—…ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ë‹¤ì‹œ ê²€í† í•´ë³´ì„¸ìš”")
        
        return "\n".join(conclusion_parts)
    
    def _calculate_total_token_usage(self) -> Dict[str, Any]:
        """ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚° - ì‹¤ì œ API ì‘ë‹µ ê¸°ë°˜"""
        total_usage = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "estimated": False
        }
        
        # token_usage_historyì—ì„œ ì‹¤ì œ ì‚¬ìš©ëŸ‰ í•©ì‚°
        if self.token_usage_history:
            for usage_record in self.token_usage_history:
                usage = usage_record.get("usage", {})
                if isinstance(usage, dict):
                    total_usage["prompt_tokens"] += usage.get("prompt_tokens", 0)
                    total_usage["completion_tokens"] += usage.get("completion_tokens", 0)
                    total_usage["total_tokens"] += usage.get("total_tokens", 0)
            
            # ì‹¤ì œ í† í° ì •ë³´ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if total_usage["total_tokens"] > 0:
                return total_usage
        
        # ì‹¤ì œ í† í° ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì¶”ì •ê°’ ì‚¬ìš© (í´ë°±)
        total_usage["estimated"] = True
        for message in self.conversation_history:
            content = message.get('content', '')
            if content:
                # ë” ì •í™•í•œ ì¶”ì •ì„ ìœ„í•´ tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
                # í˜„ì¬ëŠ” ê°„ë‹¨í•œ ì¶”ì • (í•œê¸€ì€ 2-3í† í°, ì˜ì–´ëŠ” 3-4ìë‹¹ 1í† í°)
                if message.get('role') == 'user':
                    estimated_tokens = len(content) // 3
                    total_usage["prompt_tokens"] += estimated_tokens
                elif message.get('role') == 'assistant':
                    estimated_tokens = len(content) // 3
                    total_usage["completion_tokens"] += estimated_tokens
                elif message.get('role') == 'system':
                    estimated_tokens = len(content) // 3
                    total_usage["prompt_tokens"] += estimated_tokens
                elif message.get('role') == 'tool':
                    # ë„êµ¬ ì‘ë‹µë„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë¨
                    estimated_tokens = len(content) // 3
                    total_usage["prompt_tokens"] += estimated_tokens
        
        total_usage["total_tokens"] = total_usage["prompt_tokens"] + total_usage["completion_tokens"]
        
        return total_usage
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.conversation_history.copy()
    
    def get_execution_log(self) -> List[Dict[str, Any]]:
        """ì‹¤í–‰ ë¡œê·¸ ë°˜í™˜"""
        return self.execution_log.copy()
    
    def get_reasoning_history(self) -> List[Dict[str, Any]]:
        """ì¶”ë¡  íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.reasoning_history.copy()
    
    def reset(self):
        """ì—ì´ì „íŠ¸ ìƒíƒœ ë¦¬ì…‹"""
        self.current_iteration = 0
        self.execution_log = []
        self.reasoning_history = []
        self.token_usage_history = []  # í† í° ì‚¬ìš© íˆìŠ¤í† ë¦¬ë„ ì´ˆê¸°í™”
        self._initialize_conversation()
    
    def health_check(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ë° êµ¬ì„± ìš”ì†Œ ìƒíƒœ í™•ì¸"""
        return {
            "agent_status": "healthy",
            "llm_client": self.llm_client.health_check(),
            "tools_manager": {
                "status": "healthy",
                "available_tools": len(self.tools_manager),
                "tools": self.tools_manager.get_available_tools()
            },
            "configuration": {
                "endpoint": self.endpoint,
                "model": self.model,
                "max_iterations": self.max_iterations,
                "callback": self.callback.__class__.__name__
            }
        }
    
    def __str__(self) -> str:
        """ë¬¸ìì—´ í‘œí˜„"""
        return f"ReactAgentV2(model='{self.model}', tools={len(self.tools_manager)}, iterations={self.current_iteration})"
    
    def __repr__(self) -> str:
        """ê°œë°œììš© í‘œí˜„"""
        return self.__str__()


# í¸ì˜ë¥¼ ìœ„í•œ íŒ©í† ë¦¬ í•¨ìˆ˜
def create_agent_v2(
    endpoint: str = "http://localhost:11434",
    model: str = "gpt-oss:20b",
    max_iterations: int = 10,
    callback: Optional[ReasoningCallback] = None
) -> ReactAgentV2:
    """
    ReactAgentV2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        endpoint: LLM ì„œë²„ ì—”ë“œí¬ì¸íŠ¸
        model: ì‚¬ìš©í•  ëª¨ë¸ëª…
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
        callback: ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì½œë°± ê°ì²´
        
    Returns:
        ReactAgentV2: ì´ˆê¸°í™”ëœ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
    """
    return ReactAgentV2(
        endpoint=endpoint,
        model=model,
        max_iterations=max_iterations,
        callback=callback
    )